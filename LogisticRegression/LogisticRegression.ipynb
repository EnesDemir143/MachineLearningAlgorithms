{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    temp = 1/(1+np.exp(-x))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_ofLogistic_Regression(x,y,w,b,lambda_):\n",
    "    m,n=x.shape\n",
    "    cost=0.\n",
    "    epsilon=1e-15\n",
    "\n",
    "\n",
    "    z = np.dot(x,w) +b\n",
    "    f_wb = sigmoid(z)\n",
    "    cost = -np.mean(y * np.log(f_wb+epsilon) + \n",
    "                (1-y) * np.log(1-f_wb+epsilon))\n",
    "\n",
    "\n",
    "    reg_cost = np.sum(w**2)\n",
    "    reg_cost = (reg_cost*lambda_)/(2*m)\n",
    "\n",
    "    Total_cost = cost + reg_cost        \n",
    "    return Total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiant_Drivarative(x,y,w,b,lambda_):\n",
    "    \n",
    "    m,n = x.shape\n",
    "\n",
    "    z = np.dot(x,w) + b\n",
    "    f_wb = sigmoid(z)\n",
    "\n",
    "    erorr = (f_wb - y) \n",
    "    dw = np.dot(erorr,x) + (lambda_ * w)\n",
    "    dw = np.sum(dw)/m\n",
    "\n",
    "    db = np.sum(erorr)/m\n",
    "\n",
    "    return dw,db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_Descent(x,y,w,b,iteration,learning_rate,lambda_):\n",
    "    \n",
    "    j_history = [] \n",
    "\n",
    "    for i in range(iteration):\n",
    "\n",
    "        dw , db = gradiant_Drivarative(x,y,w,b,lambda_)\n",
    "\n",
    "        w = w -learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "\n",
    "        cost = cost_ofLogistic_Regression(x,y,w,b,lambda_)\n",
    "        j_history.append(cost)\n",
    "\n",
    "        if len(j_history) > 1 and abs(j_history[-2] - j_history[-1] < 1e-9):\n",
    "            break\n",
    "        \n",
    "    return w,b,j_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(): \n",
    "    conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='Enes125223dür.',\n",
    "    database='diabates'\n",
    ")\n",
    "    \n",
    "    sorgu = 'SELECT * FROM diabetes_data'\n",
    "    df = pd.read_sql(sorgu,conn)\n",
    "    conn.close()\n",
    "\n",
    "    x=df.drop(columns=\"Outcome\").to_numpy()\n",
    "    y=df[\"Outcome\"].to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    x_mean = np.mean(X_train, axis=0)\n",
    "    std_x = np.std(X_train, axis=0)\n",
    "    X_train = (X_train - x_mean) / std_x\n",
    "    X_test = (X_test - x_mean) / std_x  \n",
    "\n",
    "\n",
    "    w = np.random.randn(X_train[0].shape[0])*0.01\n",
    "    b = 0.0\n",
    "\n",
    "    learning_rate = 0.5\n",
    "    lambda_= 0.6\n",
    "\n",
    "    iterations = 1000\n",
    "\n",
    "    final_w , final_b ,J_HİST= gradient_Descent(X_train,y_train,w,b,iterations,learning_rate,lambda_)\n",
    "\n",
    "    return final_w,final_b,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,w,b):\n",
    "\n",
    "    z = np.dot(X,w) + b\n",
    "    y_prob =sigmoid(z)\n",
    "\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    return np.sum(y_pred==y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doğruluğu: 71.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pv/pr_x9g556yxg3mhjg9g3hwj80000gn/T/ipykernel_68949/4225236017.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sorgu,conn)\n"
     ]
    }
   ],
   "source": [
    "w, b, X_test, y_test = train_logistic_regression()\n",
    "y_pred = predict(X_test, w, b)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(f\"Model doğruluğu: {acc:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
